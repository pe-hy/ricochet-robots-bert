# @package _global_

# Hydra configuration for Ricochet Robots Node Classifier
# Usage: python train_node_classifier.py [options]
# Override: python train_node_classifier.py trainer.epochs=50 training.max_lr=2e-3

defaults:
  - _self_

# Random seed for reproducibility
seed: 42

# Weights & Biases configuration
wandb:
  project: ricochet-robots-node-classifier
  name: null  # Auto-generate name if null
  save_dir: ./tmp/wandb_logs
  log_model: false

# Data configuration
data:
  train_path: data/ricochet_data/dataset.json
  board_size: 16
  batch_size: 128
  num_workers: 4

  # Split configuration (absolute numbers)
  val_size: 256      # Number of examples for validation
  test_size: 256     # Number of examples for test (0 = no test set)

  # Positional encoding
  positional_encoding: onehot  # Options: onehot, sinusoidal, normalized, learned
  positional_encoding_kwargs: {}

# Model architecture
model:
  d_model: 256
  nhead: 8
  num_layers: 6
  dim_feedforward: 1024
  dropout: 0.1
  activation: gelu

# Training configuration
training:
  max_lr: 0.001
  weight_decay: 0.01
  warmup_epochs: 20
  pos_weight: 1  # Equal weighting, no auto-computation (null would auto-compute)
  log_predictions: true

# PyTorch Lightning Trainer
trainer:
  epochs: 100
  accelerator: auto
  devices: auto
  strategy: auto
  precision: bf16-mixed
  log_every_n_steps: 50
  val_check_interval: 1.0
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  deterministic: false
  benchmark: true

# Checkpoint configuration
checkpoint:
  dirpath: ./tmp/checkpoints
  filename: robots_classifier-{epoch:02d}-{val/exact_match:.4f}
  monitor: val/exact_match
  mode: max
  save_top_k: 3
  save_last: true

# Early stopping
early_stopping:
  enabled: false
  monitor: val/exact_match
  patience: 10
  mode: max

# Hydra configuration
hydra:
  run:
    dir: ./tmp/hydra
  sweep:
    dir: ./tmp/hydra/sweep/
    subdir: "sub"
